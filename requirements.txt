# Core Libraries
pyspark         # Core PySpark library
numpy           # For numerical computations
pandas          # Data manipulation (if needed for external utilities)
scikit-learn    # For additional ML tools like scaling (if needed)
joblib          # For saving and loading encoders and scalers
matplotlib      # For data visualization (if required in EDA notebooks)
seaborn         # Advanced visualization library
plotly          # Advanced visualization library

# MLOps and Experiment Tracking
mlflow          # For experiment tracking
dvc[s3]         # For data version control with MinIO (S3 compatibility)
boto3           # AWS SDK for MinIO connection

# Metadata Management
openmetadata-ingestion     # For metadata management
PyYAML                     # For reading configuration files (used in OpenMetadata)

# Testing and Code Quality
pytest              # For testing
flake8              # For code linting
autopep8            # For automatic PEP 8 formatting
autoflak            # For removing unused imports
isort               # For sorting imports
black               # For code formatting
apache-airflow
